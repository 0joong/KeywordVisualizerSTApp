import streamlit as st
import pandas as pd
from konlpy.tag import Okt
from collections import Counter
import lib.myTextMining as tm
import lib.naverNewsCrawler as nc
import os

st.title("í‚¤ì›Œë“œ ê¸°ë°˜ í…ìŠ¤íŠ¸ ì‹œê°í™”")

# --- ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ ---
data_source = st.radio("ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”", ("CSV íŒŒì¼ ì—…ë¡œë“œ", "Naver ë‰´ìŠ¤ ê²€ìƒ‰"))

# session_state ì´ˆê¸°í™”
if "df" not in st.session_state:
    st.session_state.df = None
if "column_name" not in st.session_state:
    st.session_state.column_name = None

# --- 1. CSV ì—…ë¡œë“œ ---
if data_source == "CSV íŒŒì¼ ì—…ë¡œë“œ":
    uploaded_file = st.file_uploader("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="csv")
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        column_name = st.text_input("ë¶„ì„í•  ì»¬ëŸ¼ëª…", value="description")
        if column_name in df.columns:
            st.session_state.df = df
            st.session_state.column_name = column_name
            st.success(f"'{column_name}' ì»¬ëŸ¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
        else:
            st.error(f"'{column_name}' ì»¬ëŸ¼ì´ CSVì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# --- 2. ë‰´ìŠ¤ ê²€ìƒ‰ ---
else:
    keyword = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
    if keyword and st.button("ë‰´ìŠ¤ ê²€ìƒ‰ ë° ìˆ˜ì§‘"):
        st.info(f"ğŸ”„ '{keyword}' ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
        nc.naverNewsAPICraw(keyword)
        csv_path = f"./data/{keyword}_naver_news.csv"
        if os.path.exists(csv_path):
            df = pd.read_csv(csv_path)
            if "description" in df.columns:
                st.session_state.df = df
                st.session_state.column_name = "description"
                st.success("ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
            else:
                st.error("ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        else:
            st.error("ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨ ë˜ëŠ” íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# --- ë¶„ì„ ì„¤ì • (ì‚¬ì´ë“œë°”) ---
st.sidebar.header("ì„¤ì •")

show_freq_graph = st.sidebar.checkbox("ë¹ˆë„ìˆ˜ ê·¸ë˜í”„", value=True)
freq_word_count = st.sidebar.slider("ë‹¨ì–´ ìˆ˜", min_value=10, max_value=50, value=20)

show_wordcloud = st.sidebar.checkbox("ì›Œë“œí´ë¼ìš°ë“œ", value=True)
wordcloud_word_count = st.sidebar.slider("ë‹¨ì–´ ìˆ˜", min_value=20, max_value=500, value=50)

analyze_button = st.sidebar.button("ë¶„ì„ ì‹œì‘")

# --- ë¶„ì„ ì‹¤í–‰ ---
if analyze_button:
    if st.session_state.df is None or st.session_state.column_name is None:
        st.error("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. CSVë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ í‚¤ì›Œë“œë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”.")
    else:
        st.info("í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...")

        df = st.session_state.df
        column_name = st.session_state.column_name

        corpus_list = list(df[column_name])
        tokenizer = Okt()
        tags = ['Noun', 'Adjective', 'Verb']
        stopwords = ['ê°€', 'ë‚˜']  # ê¸°ë³¸ ë¶ˆìš©ì–´

        token_list = tm.tokenize_korean_corpus(corpus_list, tokenizer, tags, stopwords)
        counter = Counter(token_list)

        if show_freq_graph:
            st.subheader("ë‹¨ì–´ ë¹ˆë„ìˆ˜")
            top_counter = Counter(dict(counter.most_common(freq_word_count)))
            tm.visualize_barchart(top_counter, "ë‹¨ì–´ ë¹ˆë„ìˆ˜", "ë¹ˆë„ìˆ˜", "ë‹¨ì–´")

        if show_wordcloud:
            st.subheader("ì›Œë“œí´ë¼ìš°ë“œ")
            top_counter = Counter(dict(counter.most_common(wordcloud_word_count)))
            tm.visualize_wordcloud(top_counter)

